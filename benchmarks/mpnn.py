"""GIN MPNN model for graph-level prediction tasks using PyTorch Geometric."""

import argparse
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import sys

import networkx as nx
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch_geometric.data import Data
from torch_geometric.nn import GINConv, global_mean_pool


class GraphTaskDataset(Dataset):
    """Dataset for loading graph tasks generated by graph-token."""
    
    def __init__(
        self,
        data_dir: str,
        task: str,
        algorithm: str | list,
        split: str,
    ):
        """
        Args:
            data_dir: Root directory containing tasks_autograph data
            task: Task name (e.g., 'node_degree', 'edge_count', 'cycle_check')
            algorithm: Graph algorithm (e.g., 'ba', 'er', 'sbm'). Can also be
                a list/tuple of algorithms to form a union of datasets.
            split: Data split ('train', 'valid', 'test')
        """
        self.data_dir = Path(data_dir)
        self.task = task
        # normalize algorithm to either str or list
        if isinstance(algorithm, (list, tuple)):
            self.algorithm = list(algorithm)
        else:
            self.algorithm = algorithm
        self.split = split
        
        self.samples = self._load_samples()
        self.graphs = []
        self.labels = []
        self.query_nodes = []  # Store (u, v) pairs for shortest_path
        self._parse_samples()
    
    def _load_samples(self) -> List[dict]:
        """Load samples from JSON files."""
        samples = []

        # Handle both cases: data_dir as parent of tasks_autograph or as tasks_autograph itself
        if (self.data_dir / "tasks_autograph").exists():
            base = self.data_dir / "tasks_autograph" / self.task
        else:
            base = self.data_dir / self.task

        # If algorithm is a list, collect samples from each algorithm subfolder
        algo_list = self.algorithm if isinstance(self.algorithm, (list, tuple)) else [self.algorithm]

        found_any = False
        for a in algo_list:
            task_dir = base / a / self.split
            if not task_dir.exists():
                continue
            found_any = True
            for json_file in sorted(task_dir.glob("*.json")):
                with json_file.open() as f:
                    samples.extend(json.load(f))

        if not found_any:
            raise ValueError(f"Task directory not found for any algorithms {algo_list} under {base}")

        if not samples:
            raise ValueError(f"No samples found for task {self.task} in {base} for algorithms {algo_list}")

        return samples
    
    def _parse_graph_from_tokens(self, tokens: List[str]) -> Tuple[nx.Graph, int]:
        """Parse a graph from tokenized representation.
        
        Token format: <bos> u1 v1 <e> u2 v2 <e> ... <n> n1 n2 ... <q> query <p> answer <eos>
        """
        graph = nx.Graph()
        idx = 0
        
        if idx < len(tokens) and tokens[idx] == "<bos>":
            idx += 1
        
        while idx < len(tokens) and tokens[idx] != "<n>":
            token = tokens[idx]
            
            if token.startswith("<") and token.endswith(">"):
                idx += 1
                continue
            
            try:
                if idx + 1 < len(tokens):
                    try:
                        u = int(token)
                        v = int(tokens[idx + 1])
                        graph.add_edge(u, v)
                        idx += 2
                        continue
                    except ValueError:
                        pass
            except (IndexError, TypeError):
                pass
            
            idx += 1
        
        if idx < len(tokens) and tokens[idx] == "<n>":
            idx += 1
        
        while idx < len(tokens):
            token = tokens[idx]
            if token.startswith("<") and token.endswith(">"):
                break
            
            try:
                node = int(token)
                if node not in graph:
                    graph.add_node(node)
            except (ValueError, TypeError):
                pass
            idx += 1
        
        for u, v in list(graph.edges()):
            graph.add_node(u)
            graph.add_node(v)
        
        return graph, idx
    
    def _extract_query_nodes(self, tokens: List[str]) -> Optional[Tuple[int, int]]:
        """Extract query nodes from tokens for shortest_path task.
        
        Format: <q> shortest_distance u v
        Returns: (u, v) or None if not found
        """
        try:
            q_idx = tokens.index("<q>")
            if q_idx + 3 < len(tokens) and tokens[q_idx + 1] == "shortest_distance":
                try:
                    u = int(tokens[q_idx + 2])
                    v = int(tokens[q_idx + 3])
                    return (u, v)
                except (ValueError, IndexError):
                    pass
        except (ValueError, IndexError):
            pass
        return None
    
    def _extract_label(self, tokens: List[str]) -> Optional[float]:
        """Extract label from tokens (numeric or categorical).
        
        Label format: ... <p> [prefix]<value> <eos>
        Examples: "d5" -> 5, "n10" -> 10, "m15" -> 15, "yes" -> 1.0, "no" -> 0.0
        """
        try:
            p_idx = tokens.index("<p>")
        except ValueError:
            return None
        
        if p_idx + 1 >= len(tokens):
            return None
        
        label_str = tokens[p_idx + 1].lower().strip()
        
        if label_str in ["yes", "true", "1"]:
            return 1.0
        elif label_str in ["no", "false", "0"]:
            return 0.0
        
        numeric_str = "".join(c for c in label_str if c.isdigit())
        
        try:
            if numeric_str:
                return float(numeric_str)
        except ValueError:
            pass
        
        return None
    
    def _parse_samples(self):
        """Parse all samples into graphs and labels."""
        failed_count = 0
        success_count = 0
        inf_skipped = 0
        
        for i, sample in enumerate(self.samples):
            text = sample.get("text", "")
            if not text:
                failed_count += 1
                continue
            
            tokens = text.strip().split()
            
            try:
                graph, idx = self._parse_graph_from_tokens(tokens)
                label = self._extract_label(tokens)
                
                # For shortest_path, skip INF (unreachable) labels
                if self.task == "shortest_path":
                    try:
                        p_idx = tokens.index("<p>")
                        if p_idx + 1 < len(tokens) and tokens[p_idx + 1].upper() in ["INF", "INFINITY"]:
                            inf_skipped += 1
                            continue
                    except ValueError:
                        pass
                
                query_nodes = None
                if self.task == "shortest_path":
                    query_nodes = self._extract_query_nodes(tokens)
                    if query_nodes is None:
                        failed_count += 1
                        continue
                
                if graph.number_of_nodes() > 0 and label is not None:
                    self.graphs.append(graph)
                    self.labels.append(label)
                    self.query_nodes.append(query_nodes)  # None for non-shortest_path tasks
                    success_count += 1
                else:
                    failed_count += 1
                    if i < 3:
                        print(f"  Sample {i}: nodes={graph.number_of_nodes()}, label={label}")
            except Exception as e:
                failed_count += 1
                if i < 3:
                    print(f"  Sample {i} error: {e}")
        
        if success_count == 0 and failed_count > 0:
            print(f"  WARNING: Parsed {success_count} samples successfully, {failed_count} failed")
            if len(self.samples) > 0:
                print(f"  First sample text (first 200 chars): {str(self.samples[0].get('text', ''))[:200]}")
        
        if self.task == "shortest_path" and inf_skipped > 0:
            print(f"  Skipped {inf_skipped} unreachable (INF) samples for shortest_path")
    
    def _nx_to_pyg(self, graph: nx.Graph, query_nodes: Optional[Tuple[int, int]] = None) -> Data:
        """Convert NetworkX graph to PyTorch Geometric Data object.
        
        Args:
            graph: NetworkX graph
            query_nodes: (u, v) tuple for shortest_path task, None otherwise
        """
        node_features = []
        degree_dict = dict(graph.degree())
        sorted_nodes = sorted(graph.nodes())
        
        for node in sorted_nodes:
            degree = degree_dict.get(node, 0)
            features = [float(degree)]
            
            # Add query encoding for shortest_path task
            if query_nodes is not None:
                query_u, query_v = query_nodes
                is_source = 1.0 if node == query_u else 0.0
                is_target = 1.0 if node == query_v else 0.0
                features.extend([is_source, is_target])
            
            node_features.append(features)
        
        if len(node_features) == 0:
            # Fallback for empty graphs
            feature_dim = 3 if query_nodes is not None else 1
            node_features = [[0.0] * feature_dim]
        
        x = torch.tensor(node_features, dtype=torch.float)
        
        edge_list = []
        for u, v in graph.edges():
            edge_list.append([u, v])
            edge_list.append([v, u])
        
        if len(edge_list) == 0:
            edge_index = torch.tensor([[], []], dtype=torch.long)
        else:
            edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()
        
        data = Data(x=x, edge_index=edge_index)
        return data
    
    def __len__(self) -> int:
        return len(self.graphs)
    
    def __getitem__(self, idx: int) -> Tuple[Data, float]:
        graph = self.graphs[idx]
        label = self.labels[idx]
        query_nodes = self.query_nodes[idx] if idx < len(self.query_nodes) else None
        data = self._nx_to_pyg(graph, query_nodes)
        return data, torch.tensor(label, dtype=torch.float)


class GIN(nn.Module):
    """Graph Isomorphism Network (GIN) for graph-level prediction."""
    
    def __init__(
        self,
        in_features: int,
        hidden_dim: int = 64,
        num_layers: int = 4,
        out_features: int = 1,
        dropout: float = 0.5,
    ):
        """
        Args:
            in_features: Input feature dimension
            hidden_dim: Hidden layer dimension
            num_layers: Number of GIN layers
            out_features: Output dimension (1 for regression)
            dropout: Dropout rate
        """
        super().__init__()
        
        self.in_features = in_features
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.dropout = dropout
        
        self.gin_layers = nn.ModuleList()
        self.batch_norms = nn.ModuleList()
        
        nn_first = nn.Sequential(
            nn.Linear(in_features, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
        )
        self.gin_layers.append(GINConv(nn_first))
        self.batch_norms.append(nn.BatchNorm1d(hidden_dim))
        
        for _ in range(num_layers - 1):
            nn_hidden = nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim),
                nn.ReLU(),
                nn.Linear(hidden_dim, hidden_dim),
            )
            self.gin_layers.append(GINConv(nn_hidden))
            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))
        
        self.mlp = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, out_features),
        )
    
    def forward(self, data: Data) -> torch.Tensor:
        """Forward pass through GIN network.
        
        Args:
            data: PyTorch Geometric Data object with x and edge_index
        
        Returns:
            Graph-level predictions
        """
        x, edge_index, batch = data.x, data.edge_index, data.batch
        
        for gin, bn in zip(self.gin_layers, self.batch_norms):
            x = gin(x, edge_index)
            x = bn(x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = global_mean_pool(x, batch)
        
        out = self.mlp(x)
        return out


class GraphMPNNTrainer:
    """Trainer for GIN MPNN model on graph tasks."""
    
    def __init__(
        self,
        model: GIN,
        learning_rate: float = 1e-3,
        weight_decay: float = 1e-5,
        device: str = "cuda" if torch.cuda.is_available() else "cpu",
        task_type: str = "regression",
        loss: str | None = None,
    ):
        """
        Args:
            model: GIN model instance
            learning_rate: Learning rate for optimizer
            weight_decay: Weight decay for optimizer
            device: Device to train on
            task_type: "regression" or "classification"
        """
        self.model = model
        self.device = torch.device(device)
        self.model.to(self.device)
        self.task_type = task_type
        
        self.optimizer = Adam(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay,
        )
        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=100)
        # Allow caller to select loss function. If loss is None, fall back
        # to sensible defaults per task_type.
        self.loss_name = (loss or "").lower() if loss is not None else None
        if self.loss_name:
            if self.loss_name in ("bce", "bcewithlogits", "bce_with_logits"):
                self.loss_fn = nn.BCEWithLogitsLoss()
            elif self.loss_name in ("mse", "mse_loss"):
                self.loss_fn = nn.MSELoss()
            elif self.loss_name in ("mae", "l1", "l1loss"):
                self.loss_fn = nn.L1Loss()
            elif self.loss_name in ("rmse",):
                # RMSE training: take sqrt of MSE (add eps for numerical stability)
                def _rmse(pred, target):
                    mse = nn.MSELoss()(pred, target)
                    return torch.sqrt(mse + 1e-8)

                self.loss_fn = _rmse
            else:
                # Unknown loss name - fallback to defaults
                self.loss_fn = nn.BCEWithLogitsLoss() if task_type == "classification" else nn.MSELoss()
        else:
            # Default behavior: BCE for classification, MSE for regression
            self.loss_fn = nn.BCEWithLogitsLoss() if task_type == "classification" else nn.MSELoss()
    
    def train_epoch(self, dataloader: DataLoader) -> float:
        """Train for one epoch.
        
        Args:
            dataloader: Training dataloader
        
        Returns:
            Average loss
        """
        self.model.train()
        total_loss = 0.0
        num_batches = 0
        
        for batch in dataloader:
            batch = batch.to(self.device)
            
            pred = self.model(batch)
            label = batch.y.view(-1, 1)
            
            loss = self.loss_fn(pred, label)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    @torch.no_grad()
    def evaluate(self, dataloader: DataLoader) -> Dict[str, float]:
        """Evaluate on dataset.
        
        Args:
            dataloader: Evaluation dataloader
        
        Returns:
            Dictionary with metrics (loss, mae, accuracy)
        """
        self.model.eval()
        total_loss = 0.0
        total_mae = 0.0
        total_correct = 0
        total_samples = 0
        num_batches = 0
        
        for batch in dataloader:
            batch = batch.to(self.device)
            pred = self.model(batch)
            label = batch.y.view(-1, 1)
            
            loss = self.loss_fn(pred, label)
            total_loss += loss.item()
            num_batches += 1
            
            if self.task_type == "classification":
                pred_binary = (torch.sigmoid(pred) > 0.5).float()
                correct = (pred_binary == label).sum().item()
                total_correct += correct
                total_samples += label.size(0)
            else:
                mae = torch.mean(torch.abs(pred - label))
                total_mae += mae.item()
                # Optionally compute accuracy for regression-like tasks when requested
                # by rounding predictions/labels to nearest integer and comparing.
                eval_metrics = getattr(self, 'eval_metrics', None) or []
                if 'accuracy' in [m.lower() for m in (eval_metrics or [])]:
                    pred_round = torch.round(pred).to(torch.int64)
                    label_round = torch.round(label).to(torch.int64)
                    correct = (pred_round == label_round).sum().item()
                    total_correct += correct
                    total_samples += label.size(0)
        
        metrics = {
            "loss": total_loss / num_batches if num_batches > 0 else 0.0,
        }
        
        if self.task_type == "classification":
            metrics["accuracy"] = total_correct / total_samples if total_samples > 0 else 0.0
        else:
            metrics["mae"] = total_mae / num_batches if num_batches > 0 else 0.0
            eval_metrics = getattr(self, 'eval_metrics', None) or []
            if 'accuracy' in [m.lower() for m in (eval_metrics or [])]:
                metrics["accuracy"] = total_correct / total_samples if total_samples > 0 else 0.0
        
        return metrics
    
    def save_checkpoint(self, path: str):
        """Save model checkpoint."""
        torch.save(self.model.state_dict(), path)
    
    def load_checkpoint(self, path: str):
        """Load model checkpoint."""
        self.model.load_state_dict(torch.load(path, map_location=self.device))


def collate_fn(batch: List[Tuple[Data, torch.Tensor]]) -> Data:
    """Collate function for DataLoader that batches PyG Data objects."""
    graphs, labels = zip(*batch)
    
    batch_size = len(graphs)
    batch_x_list = []
    batch_edge_index_list = []
    batch_indices = []
    batch_labels = []
    
    node_offset = 0
    for i, (graph, label) in enumerate(zip(graphs, labels)):
        batch_x_list.append(graph.x)
        
        if graph.edge_index.size(1) > 0:
            edge_index = graph.edge_index + node_offset
            batch_edge_index_list.append(edge_index)
        
        batch_indices.extend([i] * graph.x.size(0))
        batch_labels.append(label)
        
        node_offset += graph.x.size(0)
    
    x = torch.cat(batch_x_list, dim=0)
    
    if batch_edge_index_list:
        edge_index = torch.cat(batch_edge_index_list, dim=1)
    else:
        edge_index = torch.tensor([[], []], dtype=torch.long)
    
    batch_tensor = torch.tensor(batch_indices, dtype=torch.long)
    y = torch.stack(batch_labels)
    
    return Data(x=x, edge_index=edge_index, batch=batch_tensor, y=y)


def main(
    data_dir: str = "/data/young/capstone/graph-learning-benchmarks/submodules/graph-token",
    task: str = "edge_count",
    algorithm: str = "ba",
    output_dir: str = "./models",
    num_epochs: int = 100,
    batch_size: int = 32,
    hidden_dim: int = 64,
    num_layers: int = 4,
    learning_rate: float = 1e-3,
    device: str = "cuda" if torch.cuda.is_available() else "cpu",
):
    """Main training script.
    
    Args:
        data_dir: Path to graph-token data directory
        task: Task name (e.g., 'edge_count', 'node_degree')
        algorithm: Graph algorithm (e.g., 'ba', 'er', 'sbm')
        output_dir: Directory to save models
        num_epochs: Number of training epochs
        batch_size: Batch size for training
        hidden_dim: Hidden dimension for GIN layers
        num_layers: Number of GIN layers
        learning_rate: Learning rate for optimizer
        device: Device to use ('cuda' or 'cpu')
    """
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print(f"Loading datasets...")
    
    try:
        train_dataset = GraphTaskDataset(data_dir, task, algorithm, "train")
        valid_dataset = GraphTaskDataset(data_dir, task, algorithm, "valid")
        test_dataset = GraphTaskDataset(data_dir, task, algorithm, "test")
    except ValueError as e:
        print(f"Error loading datasets: {e}")
        print("Make sure graph-token data is generated first.")
        return
    
    print(f"Train: {len(train_dataset)}, Valid: {len(valid_dataset)}, Test: {len(test_dataset)}")
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        collate_fn=collate_fn,
    )
    valid_loader = DataLoader(
        valid_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=collate_fn,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=collate_fn,
    )
    
    # Input features: degree (1) + query encoding (2) for shortest_path
    in_features = 3 if task == "shortest_path" else 1
    
    # Only cycle_check is binary classification; shortest_path predicts path length (regression)
    task_type = "classification" if task in ["cycle_check"] else "regression"
    
    model = GIN(
        in_features=in_features,
        hidden_dim=hidden_dim,
        num_layers=num_layers,
        out_features=1,
        dropout=0.5,
    )
    
    print(f"Model parameters: {sum(p.numel() for p in model.parameters())}")
    print(f"Task type: {task_type}")
    
    trainer = GraphMPNNTrainer(
        model, 
        learning_rate=learning_rate, 
        device=device,
        task_type=task_type
    )
    
    best_valid_loss = float("inf")
    best_model_path = output_path / "mpnn_best_model.pt"
    
    print(f"\nStarting training on {device}...")
    for epoch in range(num_epochs):
        train_loss = trainer.train_epoch(train_loader)
        valid_metrics = trainer.evaluate(valid_loader)
        trainer.scheduler.step()
        
        valid_loss = valid_metrics["loss"]
        
        if (epoch + 1) % 10 == 0:
            metrics_str = f"Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f}"
            if task_type == "classification":
                metrics_str += f" | Valid Accuracy: {valid_metrics['accuracy']:.4f}"
            else:
                metrics_str += f" | Valid MAE: {valid_metrics['mae']:.4f}"
            print(f"Epoch {epoch + 1}/{num_epochs} | {metrics_str}")
        
        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            trainer.save_checkpoint(str(best_model_path))
    
    print(f"\nLoading best model from {best_model_path}")
    trainer.load_checkpoint(str(best_model_path))
    
    test_metrics = trainer.evaluate(test_loader)
    test_loss = test_metrics["loss"]
    
    print(f"\nTest Loss: {test_loss:.4f}")
    if task_type == "classification":
        test_accuracy = test_metrics["accuracy"]
        print(f"Test Accuracy: {test_accuracy:.4f}")
    else:
        test_mae = test_metrics["mae"]
        print(f"Test MAE: {test_mae:.4f}")
    
    config = {
        "task": task,
        "algorithm": algorithm,
        "task_type": task_type,
        "hidden_dim": hidden_dim,
        "num_layers": num_layers,
        "learning_rate": learning_rate,
        "batch_size": batch_size,
        "num_epochs": num_epochs,
        "test_loss": test_loss,
    }
    
    if task_type == "classification":
        config["test_accuracy"] = test_metrics["accuracy"]
    else:
        config["test_mae"] = test_metrics["mae"]
    
    config_path = output_path / "config.json"
    with config_path.open("w") as f:
        json.dump(config, f, indent=2)
    
    print(f"Config saved to {config_path}")
    print(f"Best model saved to {best_model_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Train GIN MPNN on graph tasks")
    parser.add_argument(
        "--data_dir",
        type=str,
        default="/data/young/capstone/graph-learning-benchmarks/submodules/graph-token",
        help="Path to graph-token data directory",
    )
    parser.add_argument(
        "--task",
        type=str,
        default="edge_count",
        help="Task name (e.g., 'edge_count', 'node_degree', 'cycle_check')",
    )
    parser.add_argument(
        "--algorithm",
        type=str,
        default="ba",
        help="Graph algorithm (e.g., 'ba', 'er', 'sbm')",
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./models",
        help="Directory to save models",
    )
    parser.add_argument(
        "--num_epochs",
        type=int,
        default=100,
        help="Number of training epochs",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=32,
        help="Batch size for training",
    )
    parser.add_argument(
        "--hidden_dim",
        type=int,
        default=64,
        help="Hidden dimension for GIN layers",
    )
    parser.add_argument(
        "--num_layers",
        type=int,
        default=4,
        help="Number of GIN layers",
    )
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=1e-3,
        help="Learning rate for optimizer",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Device to use ('cuda' or 'cpu')",
    )
    
    args = parser.parse_args()
    
    main(
        data_dir=args.data_dir,
        task=args.task,
        algorithm=args.algorithm,
        output_dir=args.output_dir,
        num_epochs=args.num_epochs,
        batch_size=args.batch_size,
        hidden_dim=args.hidden_dim,
        num_layers=args.num_layers,
        learning_rate=args.learning_rate,
        device=args.device,
    )
